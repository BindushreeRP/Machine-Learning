{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899dce1b",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<H2><strong>Unsupervised Model</strong></H2>\n",
    "<br>\n",
    "~Bindushree RP\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f467f6af",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Key Summary</h3>\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "1. Marketing and Strategy team must target the users from the clusters 2, 3 and 4 consisting of about almost 75% of the population that took this survey, specifically one group of people that are very extroverted and willing to spend for specific applications and features.\n",
    "<br><br>\n",
    "2. It is also recommended that they target the population from 'Uproared' and 'Stylish_and_Social' principal components, who are mostly using their phones to stay active by visiting many social sites, actively shopping online, using their free time on entertainment applications, specifically Netflix and shopping. \n",
    "<br><br>\n",
    "3. About 20% of this population likes to use their time wisely on professional sites and applications that are work related and help in their performance.\n",
    "<br><br>\n",
    "4. About 17% of the remaining population is inclined towards staying home, watching TV, looking for specific deals and discounts in their purchases. Mostly using Facebook and music applications.\n",
    "<br><br>\n",
    "5. It is also important to look at the population within clusters 3 and 4 consisting of 45% of the population from the survey and target them for future application promotions and feature upgrades of existing applications.\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8ed3b",
   "metadata": {},
   "source": [
    "<h3>Part I: Preparation of Data and Summary of Work </h3>\n",
    "<br>\n",
    "(a) In this study, we are given a Mobile App survey taken by 1552 users of different demographics.\n",
    "We started by loading our dataset, looking at the info to understand if there were any missing\n",
    "values, learning the metrics and updating the column names based on the survey questionnaire \n",
    "given in PDF format.\n",
    "<br><br>\n",
    "(b) User Defined Functions for pca_plotter, scree_plot, and unsupervised_scaler are loaded into the notebook to initiate when needed.  \n",
    "<br><br>\n",
    "(c) We start by looking at the DataFrame analyzing the answer trends, looking at any similarities between the responses to survey questions and from the analysis, we move forward to scale, fit and transform our data using Unsupervised scaling method to get the Principal Components (PC).\n",
    "<br><br>\n",
    "(d) PC's are analyzed and named using the positive and negative affinity methodology. \n",
    "<br><br>\n",
    "(e) Once we had our PC's, we moved into clustering and then concatenate the Demographics with the Clusters and Scaled Features to build box plots and derive the analysis and recommendations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#importing all the packages#\n",
    "############################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "#importing the sklearn packages for PCA and StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "#importing dendrograms and KMeans for cluster analysis\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "#loading the dataset\n",
    "file = './__datasets/Mobile_App_Survey_Data.xlsx'\n",
    "\n",
    "df_survey = pd.read_excel(io         = file,\n",
    "                          sheet_name = 0,\n",
    "                          header     = 0)\n",
    "\n",
    "#setting print options\n",
    "pd.set_option('display.max_rows',     500)\n",
    "pd.set_option('display.max_columns',  500)\n",
    "pd.set_option('display.width',        1000)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b42b08",
   "metadata": {},
   "source": [
    "<h3>User Defined Functions</h3>\n",
    "<br>\n",
    "User defined functions for PCA plot, Scree plot and unsupervised scalar. PCA plots help represent multivariate data table into smaller sets of variables that help observe the trends, clusters, and outliers. They also help understand the relationship between each observation, variables and among the variables. Scree plots help analyze our findings based on the user survey. They help us in determining the number of components that are explaining the variance and adding value to our findings or research. Unsupervised scaler is helping us scale, fit and transform all the variables by finding interpretations based on the inputs provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c89aef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "###############\n",
    "# pca_plotter #\n",
    "###############\n",
    "\n",
    "# optional color scheme\n",
    "colors_lst = [\"#476A2A\", \"#7851B8\", \"#BD3430\", \"#4A2D4E\", \"#875525\",\n",
    "              \"#A83683\", \"#4E655E\", \"#853541\", \"#3A3120\", \"#535D8E\"]\n",
    "\n",
    "\n",
    "# pca_plotter\n",
    "def pca_plotter(bunch,\n",
    "                colors  = None,\n",
    "                x_label = \"First principal component\",\n",
    "                y_label = \"Second principal component\"):\n",
    "    \"\"\"\n",
    "PARAMETERS\n",
    "----------\n",
    "bunch        : Bunch object to be used in PCA\n",
    "colors       : color coding for target labels, default None\n",
    "x_label      : x-label for PC 0, default \"First principal component\"\n",
    "y_label      : y-label for PC 1, default \"Second principal component\"\n",
    "\"\"\"\n",
    "\n",
    "    # INSTANTIATING a PCA object\n",
    "    pca = PCA(n_components = 2,\n",
    "              random_state = 219)\n",
    "\n",
    "\n",
    "    # FITTING and TRANSFORMING the data\n",
    "    dataset_pca = pca.fit_transform(bunch.data)\n",
    "\n",
    "    \n",
    "    # setting figure options\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xlim(dataset_pca[:, 0].min(), dataset_pca[:, 0].max())\n",
    "    plt.ylim(dataset_pca[:, 1].min(), dataset_pca[:, 1].max())\n",
    "\n",
    "\n",
    "    # data vizualization\n",
    "    for i in range(len(bunch.data)):\n",
    "\n",
    "        plt.text(dataset_pca[i, 0],\n",
    "                 dataset_pca[i, 1],\n",
    "                 str(bunch.target[i]),\n",
    "                 color = colors[bunch.target[i]],\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.xlabel(xlabel = x_label)\n",
    "    plt.ylabel(ylabel = y_label)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "##############\n",
    "# scree_plot #\n",
    "##############\n",
    "def scree_plot(pca_object, export = False):\n",
    "    # building a scree plot\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:\n",
    "    \n",
    "        # exporting the plot\n",
    "        plt.savefig('./analysis_images/top_customers_correlation_scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874a432",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# unsupervised_scaler #\n",
    "#######################\n",
    "\n",
    "def unsupervised_scaler(df):\n",
    "    \"\"\"\n",
    "    Standardizes a dataset (mean = 0, variance = 1). Returns a new DataFrame.\n",
    "    Requires sklearn.preprocessing.StandardScaler()\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df     | DataFrame to be used for scaling\n",
    "    \"\"\"\n",
    "\n",
    "    # INSTANTIATING a StandardScaler() object\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "\n",
    "    # FITTING the scaler with the data\n",
    "    scaler.fit(df)\n",
    "\n",
    "\n",
    "    # TRANSFORMING our data after fit\n",
    "    x_scaled = scaler.transform(df)\n",
    "\n",
    "    \n",
    "    # converting scaled data into a DataFrame\n",
    "    new_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "    # reattaching column names\n",
    "    new_df.columns = df.columns\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffcd40",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>DataFrame Analysis</h3>\n",
    "<br>\n",
    "1. Looking at the information of Mobile App Survey DataFrame to understand the data types, presence of any null values and the features present.\n",
    "<br><br>\n",
    "2. Analysis drawn from descriptive statistics: From questions Q24 through Q26, it can be observed that the 75% of values are less than average, it is possible that the users who took the survey may have randomly selected one of the available options. Also, it is observed that most of the 50% values are either 2(agree) or 3(somewhat agree). Hence, it is important that we scale these values both horizontally and vertically to remove any bias that may be present before running the PCA analysis.\n",
    "<br><br>\n",
    "3. To make the analysis and columns readable, we have renamed the columns to the corresponding question in the survey.\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1dc662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the dataset info\n",
    "df_survey.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1537c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the descriptive statistics\n",
    "df_survey.describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriving the columns to rename them in the next step\n",
    "df_survey.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3237dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns exception being Q24 through Q26\n",
    "df_survey.columns = ['caseID', 'age', 'iphone', 'ipad', 'android', 'blackberry', \n",
    "                     'nokia', 'windows', 'hp', 'tablet', 'other_phone', 'none_phone', \n",
    "                     'music', 'tv_checkin', 'entertainment', 'tv_show', 'gaming', \n",
    "                     'social', 'news', 'shopping', 'specific_news', 'other_apps', \n",
    "                     'none_apps', 'total_apps', 'free_apps', 'visit_facebook', \n",
    "                     'visit_twitter', 'visit_myspace', 'visit_pandora', \n",
    "                     'visit_vevo', 'visit_youtube', 'visit_aol', 'visit_lastfm',\n",
    "                     'visit_yahoo', 'visit_imdb', 'visit_linkedin', \n",
    "                     'visit_netflix', 'q24r1', 'q24r2', 'q24r3', 'q24r4', \n",
    "                     'q24r5', 'q24r6', 'q24r7', 'q24r8', 'q24r9', 'q24r10', \n",
    "                     'q24r11', 'q24r12', 'q25r1', 'q25r2', 'q25r3', 'q25r4', \n",
    "                     'q25r5', 'q25r6', 'q25r7', 'q25r8', 'q25r9', 'q25r10', \n",
    "                     'q25r11', 'q25r12', 'q26r18', 'q26r3', 'q26r4', 'q26r5', \n",
    "                     'q26r6', 'q26r7', 'q26r8', 'q26r9', 'q26r10', 'q26r11', \n",
    "                     'q26r12', 'q26r13', 'q26r14', 'q26r15', 'q26r16', 'q26r17', \n",
    "                     'level_of_education', 'marital_status', 'no_children', \n",
    "                     'children_under6', 'children_6to12', 'children_13to17', \n",
    "                     'children_over18', 'race', 'hispanic_latino', 'annual_income', 'gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdeeda",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Histograms and their analysis:</h3>\n",
    "\n",
    "Histograms help analyze the skewness and help analyze if any logarithmic transformations are needed. Looking at the Histograms, we could see some skewness with few demographic features, however, we did not transform any values into logarithmic values as the values were imputed in the form of response numbers, hence our dataset does not require transformations.\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8f98e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#setting a figure size\n",
    "fig, ax = plt.subplots(figsize = (12, 90))\n",
    "\n",
    "\n",
    "#initializing counter\n",
    "count = 0\n",
    "\n",
    "\n",
    "#looping to create visualizations\n",
    "for col in df_survey:\n",
    "\n",
    "    #if condition to break\n",
    "    if count == 88:\n",
    "        break\n",
    "    \n",
    "    #increasing count\n",
    "    count += 1\n",
    "    \n",
    "    #preparing histograms\n",
    "    plt.subplot(30, 3, count)\n",
    "    sns.histplot(x = df_survey[col],)\n",
    "\n",
    "\n",
    "#formatting, saving, and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('./__analysis_images/surveys_df_histograms.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b97a1",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Part II: Scaling of non-demographic features: </h3>\n",
    "<br>\n",
    "1. Survey questions 24 through 26 with high variance in responses scaled using unsupervised scaler, and the scaled data is further used for the PCA analysis and building the principal components. \n",
    "<br><br>\n",
    "2. All the other non-demographic purchase trend features are also scaled using unsupervised scaler and both the scaled datasets are combined into one DataFrame.\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsetting the questions from 24 through 26 to scale\n",
    "df_q24to26 = df_survey.loc[ : , ['q24r1', 'q24r2', 'q24r3', 'q24r4', 'q24r5', \n",
    "                                 'q24r6', 'q24r7', 'q24r8', 'q24r9', 'q24r10', \n",
    "                                 'q24r11', 'q24r12','q25r1', 'q25r2', 'q25r3', \n",
    "                                 'q25r4', 'q25r5', 'q25r6', 'q25r7', 'q25r8', \n",
    "                                 'q25r9', 'q25r10', 'q25r11', 'q25r12', 'q26r18', \n",
    "                                 'q26r3', 'q26r4', 'q26r5', 'q26r6', 'q26r7', \n",
    "                                 'q26r8', 'q26r9', 'q26r10', 'q26r11', 'q26r12', \n",
    "                                 'q26r13', 'q26r14', 'q26r15', 'q26r16', 'q26r17']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b2ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fitting and transforming the data\n",
    "df_survey_scaled = scaler.fit_transform(df_q24to26.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd16eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transposing the results\n",
    "df_survey_scaled.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1915ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the scaled data into dataframe\n",
    "df_scaled = pd.DataFrame(data=df_survey_scaled)\n",
    "\n",
    "#df_scaled.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e25f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns\n",
    "df_scaled.columns = ['q24r1', 'q24r2', 'q24r3', 'q24r4', 'q24r5', \n",
    "                     'q24r6', 'q24r7', 'q24r8', 'q24r9', 'q24r10', \n",
    "                     'q24r11', 'q24r12','q25r1', 'q25r2', 'q25r3', \n",
    "                     'q25r4', 'q25r5', 'q25r6', 'q25r7', 'q25r8', \n",
    "                     'q25r9', 'q25r10', 'q25r11', 'q25r12', 'q26r18', \n",
    "                     'q26r3', 'q26r4', 'q26r5', 'q26r6', 'q26r7', \n",
    "                     'q26r8', 'q26r9', 'q26r10', 'q26r11', 'q26r12', \n",
    "                     'q26r13', 'q26r14', 'q26r15', 'q26r16', 'q26r17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the results\n",
    "#df_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9baeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the demographic data and unscaled q24 to 26 from original dataset\n",
    "drop_unscaled_demographics = ['q24r1', 'q24r2', 'q24r3', 'q24r4', 'q24r5', \n",
    "                              'q24r6', 'q24r7', 'q24r8', 'q24r9', 'q24r10', \n",
    "                              'q24r11', 'q24r12','q25r1', 'q25r2', 'q25r3', \n",
    "                              'q25r4', 'q25r5', 'q25r6', 'q25r7', 'q25r8', \n",
    "                              'q25r9', 'q25r10', 'q25r11', 'q25r12', 'q26r18', \n",
    "                              'q26r3', 'q26r4', 'q26r5', 'q26r6', 'q26r7', \n",
    "                              'q26r8', 'q26r9', 'q26r10', 'q26r11', 'q26r12', \n",
    "                              'q26r13', 'q26r14', 'q26r15', 'q26r16', 'q26r17',\n",
    "                              'caseID', 'age', 'level_of_education', \n",
    "                              'marital_status', 'no_children', 'children_under6', \n",
    "                              'children_6to12', 'children_13to17', 'children_over18', 'race',\n",
    "                              'hispanic_latino', 'annual_income', 'gender']\n",
    "\n",
    "df_mobile_app_survey = df_survey.drop(drop_unscaled_demographics,\n",
    "                                      axis = 1)\n",
    "\n",
    "df_mobile_app_survey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb9a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the unsupervised_scaler function on the rest of the dataset\n",
    "scaled_purchases = unsupervised_scaler(df = df_mobile_app_survey)\n",
    "\n",
    "\n",
    "#checking pre- and post-scaling variance\n",
    "#print(np.var(df_mobile_app_survey), '\\n\\n')\n",
    "#print(np.var(scaled_purchases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c47488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatting the scaled q24 to q26 and the other scaled dataset as above\n",
    "df_mobileapp = pd.concat([scaled_purchases,df_scaled],\n",
    "                         axis=1)\n",
    "\n",
    "#checking the shape\n",
    "df_mobileapp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41f706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#printing the first 5 rows of scaled DataFrame\n",
    "#df_mobileapp.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5153f6",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3> Part III: Principal Components Analysis:</h3>\n",
    "<br>\n",
    "In this section, we create Principal Components from the scaled DataFrame. Since our DataFrame has high features, we are limiting the n_components to 10 to build our component analysis to check each components explained variance ratio. Explained variance helps us understand how much of variance in the features are explained by each principal component chosen. \n",
    "\n",
    "From the constructed scree plot, we can conclude that the first three components are the suggested components for us to use in our analysis, as these are the components explaining the most variance of about 20%, despite the suggested 80%, hence proceeding with three components as these are the components that are adding value and building our DataFrame for clustering.\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1717e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating a PCA object with 10 principal components\n",
    "pca = PCA(n_components = 10,\n",
    "          random_state = 219)\n",
    "\n",
    "\n",
    "#fitting and transforming the scaled data\n",
    "survey_pca = pca.fit_transform(df_mobileapp)\n",
    "\n",
    "\n",
    "#comparing dimensions of each DataFrame\n",
    "print(\"Original shape:\", df_mobileapp.shape)\n",
    "print(\"PCA shape     :\", survey_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8018372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter for component number\n",
    "component_number = 0\n",
    "\n",
    "#looping over principal components and printing results\n",
    "for variance in pca.explained_variance_ratio_:\n",
    "    component_number += 1\n",
    "    \n",
    "    print(f\"PC {component_number}: {variance.round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733fee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the scree_plot function\n",
    "scree_plot(pca_object  = pca,\n",
    "           export      = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51286595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating new model using first 3 pincipal components\n",
    "pca_3 = PCA(n_components = 3,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "#fitting and transforming the scaled data \n",
    "survey_pca_3 = pca_3.fit_transform(df_mobileapp)\n",
    "\n",
    "\n",
    "#calling the scree plot user defined function\n",
    "scree_plot(pca_object=pca_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6192f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transposing pca components\n",
    "factor_loadings_df = pd.DataFrame(np.transpose(pca.components_.round(decimals = 2)))\n",
    "\n",
    "#renaming rows as the original dataset\n",
    "factor_loadings_df = factor_loadings_df.set_index(df_mobileapp.columns)\n",
    "\n",
    "#printing and checking teh results\n",
    "#print(factor_loadings_df)\n",
    "\n",
    "#saving the dataset to excel\n",
    "#factor_loadings_df.to_excel('./__analysis_results/customer_factor_loadings_appsurvey.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5151821",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Principal Components:</h3><br>\n",
    "Based on the strongest correlations between the components and presented questions of almost 20%, the principal components were analyzed from the extracted report as below: \n",
    "\n",
    "<strong>Principal Component 1:</strong><br>\n",
    "9.7% of explained variance. Most of the questions within this component were for specific applications like music, social networking sites, shopping and gaming. Positive affinity was for questions with disagreement about music choices and mostly Q24 and Q25.\n",
    "<br><br>\n",
    "<strong>Principal Component 2:</strong><br>\n",
    "6.3% of explained variance. This component reflects negatively on having less and feel that less is more. They reject fancy and stylish lifestyle and are a minimalistic group that is not tech savvy. But they use very few modern platforms for entertainment.\n",
    "<br><br>\n",
    "<strong>Principal Component 3:</strong><br>\n",
    "3.8% of explained variance. They are uproar about having luxury apps, like using many applications and they showcased high positive affinity for questions 24 and 25, with maximum negative affinity in question 26 which emphasizes on having more applications and being able to shop online and they tend to spend more time on entertainment and shopping than on other minimalistic lifestyle.\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ac82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns after analysing the excel with positive and negative affinity\n",
    "factor_loadings_df.columns = ['Stylish_and_Social',\n",
    "                              'Not_Tech_savvy',\n",
    "                              'Uproared',\n",
    "                              'Moneyandtime_savers',\n",
    "                              '4',\n",
    "                              '5',\n",
    "                              '6',\n",
    "                              '7',\n",
    "                              '8',\n",
    "                              '9']\n",
    "\n",
    "#checking the result\n",
    "#factor_loadings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f018ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to a dataframe\n",
    "survey_pca = pd.DataFrame(survey_pca)\n",
    "\n",
    "\n",
    "#renaming the columns\n",
    "survey_pca.columns = factor_loadings_df.columns\n",
    "\n",
    "\n",
    "#checking the results\n",
    "#survey_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b55ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transposing pca_3 components\n",
    "factor_loadings_3 = pd.DataFrame(np.transpose(pca_3.components_.round(decimals = 2)))\n",
    "\n",
    "\n",
    "#renaming rows as original features\n",
    "factor_loadings_3 = factor_loadings_3.set_index(df_mobileapp.columns)\n",
    "\n",
    "\n",
    "#checking the result\n",
    "#print(factor_loadings_3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the columns\n",
    "factor_loadings_3.columns = ['Stylish_and_Social',\n",
    "                             'Not_Tech_savvy',\n",
    "                             'Uproared',]\n",
    "\n",
    "#checking the results\n",
    "factor_loadings_3.head(n=5).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2541006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#factor strengths per customer is analysed by tranforming\n",
    "factor_loadings = pca_3.transform(df_mobileapp)\n",
    "\n",
    "\n",
    "#converting to a DataFrame\n",
    "df_factor_loadings = pd.DataFrame(factor_loadings)\n",
    "\n",
    "\n",
    "#renaming columns\n",
    "df_factor_loadings.columns = factor_loadings_3.columns\n",
    "\n",
    "\n",
    "#checking results\n",
    "df_factor_loadings.head(n=5).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ce163",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3> Part IV: Clustering:</h3>\n",
    "<br>\n",
    "The number of clusters were decided after running the algorithm multiple times. Once we identified the optimal equilibrium in number of observations for every group, we maintained it. \n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if there is variance amongst clusters\n",
    "np.var(df_factor_loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d36810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#applying the unsupervised_scaler function\n",
    "pca_scaled = unsupervised_scaler(df = df_factor_loadings)\n",
    "\n",
    "\n",
    "#checking variance before and after scaling\n",
    "print(np.var(df_factor_loadings), '\\n\\n')\n",
    "print(np.var(pca_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7041d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping data based on Ward distance\n",
    "standard_mergings_ward = linkage(y = pca_scaled,\n",
    "                                 method = 'ward',\n",
    "                                 optimal_ordering = True)\n",
    "\n",
    "\n",
    "#setting plot size\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "#developing a dendrogram\n",
    "dendrogram(Z = standard_mergings_ward,\n",
    "           leaf_rotation = 90,\n",
    "           leaf_font_size = 6)\n",
    "\n",
    "\n",
    "#rendering the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating KMeans object with four clusters\n",
    "customers_k_pca = KMeans(n_clusters   = 4,\n",
    "                        random_state  = 219)\n",
    "\n",
    "\n",
    "#fitting the above object to the scaled data\n",
    "customers_k_pca.fit(pca_scaled)\n",
    "\n",
    "\n",
    "#converting clusters to a dataframe\n",
    "customers_kmeans_pca = pd.DataFrame({'Cluster': customers_k_pca.labels_})\n",
    "\n",
    "\n",
    "#checking the results\n",
    "print(customers_kmeans_pca.iloc[: , 0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing cluster centers\n",
    "centroids_pca = customers_k_pca.cluster_centers_\n",
    "\n",
    "\n",
    "#creating dataframe from cluster centers\n",
    "centroids_pca_df = pd.DataFrame(centroids_pca)\n",
    "\n",
    "\n",
    "#renaming principal components\n",
    "centroids_pca_df.columns = ['Stylish_and_Social',\n",
    "                            'Not_Tech_savvy',\n",
    "                            'Uproared']\n",
    "\n",
    "\n",
    "#checking results with PC's in columns and clusters in rows\n",
    "centroids_pca_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinating cluster memberships with principal components\n",
    "clst_pca_df = pd.concat([customers_kmeans_pca,\n",
    "                          df_factor_loadings],\n",
    "                          axis = 1)\n",
    "\n",
    "\n",
    "#concatinating pca-clusters and demographic information\n",
    "final_pca_clust_df = pd.concat([df_survey.loc[ : , ['age', 'level_of_education', \n",
    "                                                    'marital_status', 'no_children', \n",
    "                                                    'children_under6', 'children_6to12', \n",
    "                                                    'children_13to17', 'children_over18',\n",
    "                                                    'race','hispanic_latino', \n",
    "                                                    'annual_income', 'gender']],\n",
    "                                clst_pca_df.round(decimals = 2)],\n",
    "                                axis = 1)\n",
    "\n",
    "\n",
    "#renaming columns\n",
    "final_pca_clust_df.columns = ['age', \n",
    "                              'level_of_education', \n",
    "                              'marital_status', \n",
    "                              'no_children', \n",
    "                              'children_under6', \n",
    "                              'children_6to12',\n",
    "                              'children_13to17', \n",
    "                              'children_over18',\n",
    "                              'race',\n",
    "                              'hispanic_latino',\n",
    "                              'annual_income', \n",
    "                              'gender',\n",
    "                              'Cluster',\n",
    "                              'Stylish_and_Social',\n",
    "                              'Not_Tech_savvy',\n",
    "                              'Uproared']\n",
    "\n",
    "\n",
    "#checking the results\n",
    "final_pca_clust_df.head(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming age column values\n",
    "age_names = {1 : 'Under 18',\n",
    "             2 : '18-24',\n",
    "             3 : '25-29',\n",
    "             4 : '30-34',\n",
    "             5 : '35-39',\n",
    "             6 : '40-44',\n",
    "             7 : '45-49',\n",
    "             8 : '50-54',\n",
    "             9 : '55-59',\n",
    "             10: '60-64',\n",
    "             11: '65 or over'}\n",
    "\n",
    "\n",
    "final_pca_clust_df['age'].replace(age_names, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "#renaming level of education column values\n",
    "level_of_education_names = {1 : 'Some high school',\n",
    "                            2 : 'High school graduate',\n",
    "                            3 : 'Some college',\n",
    "                            4 : 'College graduate',\n",
    "                            5 : 'Some post-graduate studies',\n",
    "                            6 : 'Post graduate degree'}\n",
    "\n",
    "final_pca_clust_df['level_of_education'].replace(level_of_education_names, inplace = True)\n",
    "\n",
    "\n",
    "#renaming marital status column values\n",
    "marital_status_names =     {1 : 'Married',\n",
    "                            2 : 'Single',\n",
    "                            3 : 'Single with a partner',\n",
    "                            4 : 'Separated/Widowed/Divorced'}\n",
    "\n",
    "\n",
    "final_pca_clust_df['marital_status'].replace(marital_status_names, inplace = True)\n",
    "\n",
    "#renaming race column values\n",
    "race_names =     {1 : 'White or caucasian',\n",
    "                  2 : 'Black or african amarican',\n",
    "                  3 : 'Asian',\n",
    "                  4 : 'Native Hawaiian or Other Pacifier Islander',\n",
    "                  5 : 'American Indian or Alaska Native',\n",
    "                  6 : 'Other race'}\n",
    "\n",
    "\n",
    "final_pca_clust_df['race'].replace(race_names, inplace = True)\n",
    "\n",
    "#renaming hispanic_latino column values\n",
    "hispanic_latino_names  =     {1 : 'Yes',\n",
    "                              2 : 'No'}\n",
    "\n",
    "\n",
    "final_pca_clust_df['hispanic_latino'].replace(hispanic_latino_names, inplace = True)\n",
    "\n",
    "#renaming annual_income column values\n",
    "annual_income_names =    {1 : \"<$10\",\n",
    "                          2 : \"$10-$14\",\n",
    "                          3 : \"$15-$19\",\n",
    "                          4 : \"$20-$29\",\n",
    "                          5 : \"$30-$39\",\n",
    "                          6 : \"$40-$49\",\n",
    "                          7 : \"$50-$59\",\n",
    "                          8 : \"$60-$69\",\n",
    "                          9 : \"$70-$79\",\n",
    "                          10 :\"$80-$89\",\n",
    "                          11 :\"$90-$99\",\n",
    "                          12 :\"$100-$124\",\n",
    "                          13 :\"$125-$149\",\n",
    "                          14 :\"$150>\"}\n",
    "\n",
    "\n",
    "final_pca_clust_df['annual_income'].replace(annual_income_names, inplace = True)\n",
    "\n",
    "#renaming gender column values\n",
    "gender_names  =     {1 : 'Male',\n",
    "                     2 : 'Female'}\n",
    "\n",
    "\n",
    "final_pca_clust_df['gender'].replace(gender_names, inplace = True)\n",
    "\n",
    "\n",
    "#renaming cluster column values\n",
    "cluster_names = {0 : 'Cluster 1',\n",
    "                 1 : 'Cluster 2',\n",
    "                 2 : 'Cluster 3',\n",
    "                 3 : 'Cluster 4'}\n",
    "\n",
    "\n",
    "final_pca_clust_df['Cluster'].replace(cluster_names, inplace = True)\n",
    "\n",
    "\n",
    "#adding a productivity step\n",
    "data_df = final_pca_clust_df\n",
    "\n",
    "\n",
    "#checking results\n",
    "data_df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6a461",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<h3>Box Plot Analysis:</h3>\n",
    "\n",
    "Within <strong>Gender</strong> category, our potential clients appear to behave similarly in the principal components we have identified. Especially for Uproared and Not_Tech_savvy there is a behavioral pattern, which may indicate that we can structure an appropriate strategy based on gender for these two components.\n",
    "\n",
    "The <strong>marital status</strong> of our potential clients is probably not related to their preferences for applications. This is particularly verified for <strong>Stylish</strong> and <strong>Not Tech savvy</strong>, while <strong>Uproared</strong> demonstrate to be more constant. Basing a marketing strategy for this specific category will probably not bring any kind of result.\n",
    "\n",
    "It is not suggested to structure the marketing strategy based on <strong>race</strong> category. Even though we can see a certain similarity on the behavior, there is no clear pattern in terms of preferences for application downloading. While looking at the correlation of race with the type of phone, it says a different story with good probability of buying application services.\n",
    "\n",
    "It was also observed that the <strong>level of education</strong> plays a role on whether customers are willing to pay or not pay for applications. Based on the level of education, we can also see how inclined one can be to buy the services offered.\n",
    "\n",
    "Cluster 3 showcases a good response in the gender and marital status demographics for the stylish and social principal component. This group will be inclined towards application purchases given their interests in having good phone, entertainment and shopping applications. It is also noteworthy that this cluster of survey responders may be of the young to middle aged population that likes to keep up with the new trends and shows.\n",
    "\n",
    "Clusters 4 showcases god response in the gender and marital status for the uproar principal component. These are the group of people interested in keeping up with the trends and rejecting Q25. They are more inclined towards application purchases than taking out time and working on their needs the hard way. These group of people could be on the move always and need the extra application features to live up with the current affairs and trends.\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b79f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#Gender and Stylish_and_Social#\n",
    "###############################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14, 10))\n",
    "sns.boxplot(x    = 'gender',\n",
    "            y    = 'Stylish_and_Social',\n",
    "            hue  = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "#formatting and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###########################\n",
    "#Gender and Not_Tech_savvy#\n",
    "###########################\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14, 10))\n",
    "sns.boxplot(x    = 'gender',\n",
    "            y    = 'Not_Tech_savvy',\n",
    "            hue  = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "#formatting and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####################\n",
    "#Gender and uproared#\n",
    "#####################\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x    = 'gender',\n",
    "            y    = 'Uproared',\n",
    "            hue  = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "# formatting and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "#marital_status and Stylish_and_Social#\n",
    "#######################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14, 10))\n",
    "sns.boxplot(x    = 'marital_status',\n",
    "            y    = 'Stylish_and_Social',\n",
    "            hue  = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "#formatting and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###################################\n",
    "#marital_status and Not_Tech_savvy#\n",
    "###################################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14, 10))\n",
    "sns.boxplot(x    = 'marital_status',\n",
    "            y    = 'Not_Tech_savvy',\n",
    "            hue  = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "#formatting and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#############################\n",
    "#marital_status and Uproared#\n",
    "#############################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x    = 'marital_status',\n",
    "            y    = 'Uproared',\n",
    "            hue  = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "# formatting and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b142cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#Race and Stylish_and_Social#\n",
    "#############################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14, 10))\n",
    "sns.boxplot(x    = 'race',\n",
    "            y    = 'Stylish_and_Social',\n",
    "            hue  = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "#formatting and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#########################\n",
    "#Race and Not_Tech_savvy#\n",
    "#########################\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (14, 10))\n",
    "sns.boxplot(x    = 'race',\n",
    "            y    = 'Not_Tech_savvy',\n",
    "            hue  = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "#formatting and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "###################\n",
    "#Race and Uproared#\n",
    "###################\n",
    "\n",
    "# race correlation with the uproared group\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "sns.boxplot(x    = 'race',\n",
    "            y    = 'Uproared',\n",
    "            hue  = 'Cluster',\n",
    "            data = data_df)\n",
    "\n",
    "\n",
    "# formatting and displaying the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
