{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546d0acb",
   "metadata": {},
   "source": [
    "<h2><strong>Classification Model Development</strong></h2>\n",
    "<br>\n",
    "<h3>~ <strong>Bindushree R P</strong></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a1d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rand\n",
    "import numpy as np\n",
    "\n",
    "#importing gender guesser\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "#importing all the sklearn and stat model packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#importing the sklearn packages for classification model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "#loading data \n",
    "file = \"../path_practice/__storage/GOT_character_predictions.xlsx\"\n",
    "\n",
    "df_got = pd.read_excel(io         = file,\n",
    "                       header     = 0,\n",
    "                       sheet_name = 0)\n",
    "\n",
    "# setting random seed\n",
    "rand.seed(a = 327)\n",
    "\n",
    "#Setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width',1000)\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "\n",
    "#displaying first 5 rows of the dataset\n",
    "df_got.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7255aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the number of missing values\n",
    "df_got.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22dc14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriving the dataset information\n",
    "df_got.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e978f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data dictionary\n",
    "file1 = \"../path_practice/__storage/GOT_data_dictionary.xlsx\" \n",
    "\n",
    "df_got_data_dict = pd.read_excel(io         = file1,\n",
    "                                header     = 0,\n",
    "                                sheet_name = 0)\n",
    "\n",
    "#displaying the data dictionary\n",
    "df_got_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbee179",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the previous step, we loaded the dictionary dataset in order to analyze the features that happen after event horizon (if survived). After this we shall drop all the features that have occured or collected after the event horizon. However, we did not find any such features in our dataset, Popularity does strike like one but it is not necessarily based on is alive feature. Hence we would not drop any features from our dataset and nothing is considered to have taken place after event horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe03e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the missing values\n",
    "df_got.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ac810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysing the available title column values to check if there are any duplicates\n",
    "df_got.loc[: ,'title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba29260",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#user-defined functions\n",
    "\n",
    "\n",
    "#function for missing value flagger\n",
    "\n",
    "def mv_flagger(df):\n",
    "    \"\"\"\n",
    "Flags all columns that have missing values with 'm-COLUMN_NAME'.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "df : DataFrame to flag missing values\n",
    "\n",
    "\n",
    "RETURNS\n",
    "-------\n",
    "DataFrame with missing value flags.\"\"\"\n",
    "\n",
    "\n",
    "    for col in df:\n",
    "\n",
    "        if df[col].isnull().astype(int).sum() > 0:\n",
    "            df['m_'+col] = df[col].isnull().astype(int)\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# text_split_feature\n",
    "\n",
    "def text_split_feature(col, df, sep=' ', new_col_name='number_of_names'):\n",
    "    \"\"\"\n",
    "Splits values in a string Series (as part of a DataFrame) and sums the number\n",
    "of resulting items. Automatically appends summed column to original DataFrame.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "col          : column to split\n",
    "df           : DataFrame where column is located\n",
    "sep          : string sequence to split by, default ' '\n",
    "new_col_name : name of new column after summing split, default\n",
    "               'number_of_names'\n",
    "\"\"\"\n",
    "    \n",
    "    df[new_col_name] = 0\n",
    "    \n",
    "    \n",
    "    for index, val in df.iterrows():\n",
    "        df.loc[index, new_col_name] = len(df.loc[index, col].split(sep = ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running the missing value flagger function to create columns for missing values\n",
    "df_got_translated = mv_flagger(df = df_got)\n",
    "\n",
    "#retrieving the columns\n",
    "df_got_translated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979359bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_got_corr = df_got.corr(method= \"pearson\").round(decimals=2)\n",
    "\n",
    "df_got_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f199f823",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# developing histograms for numerical variables to check for skewness\n",
    "sns.histplot(data   = df_got,\n",
    "             x      = 'dateOfBirth',\n",
    "             kde    = True,\n",
    "             binwidth= 1000)\n",
    "#.set(ylim   = (0))\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"original date of birth distribution\")\n",
    "plt.xlabel(xlabel = \"DOB\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed620a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data   = df_got,\n",
    "             x      = 'age',\n",
    "             kde    = True,\n",
    "             binwidth= 1000)\n",
    "\n",
    "\n",
    "# title and axis labels\n",
    "plt.title(label   = \"original age distribution\")\n",
    "plt.xlabel(xlabel = \"age\") # avoiding using dataset labels\n",
    "plt.ylabel(ylabel = \"Count\")\n",
    "\n",
    "# displaying the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2597086",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>\n",
    "\n",
    "From the above histograms, we can say that both <strong>DateofBirth</strong> and <strong>Age</strong> is skewed and it must be imputed with median. But also it is a posibility to create a new column with a nested condition to check if the value in either column Age or DOB is greater than zero and if not to create a missing value in a brand new column. Need to look into this, for now I have imputed the missing values with <strong>median</strong>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4373113",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<strong>Imputing missing values</strong><br>\n",
    "\n",
    "1. Age             - imputed with median<br>\n",
    "2. Date of birth   - imputed with median<br>\n",
    "3. Title           - imputed with unknown<br>\n",
    "4. Culture         - imputed with unknown<br>\n",
    "5. Mother          - imputed with unknown<br>\n",
    "6. Father          - imputed with unknown<br>\n",
    "7. Heir            - imputed with unknown<br>\n",
    "8. House           - Used nested conditional to fill the top houses and imputed the rest with Unknown<br>\n",
    "9. Spouse          - imputed with unknown<br>\n",
    "10. isAliveMother  - imputed with 0<br>\n",
    "11. isAliveFather  - imputed with 0<br>\n",
    "12. isAliveHeir    - imputed with 0<br>\n",
    "13. isAliveSpouse  - imputed with 0<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ad813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing missing values for age \n",
    "imputed_age = df_got_translated['age'].median()\n",
    "df_got_translated['age'] = df_got_translated['age'].fillna(imputed_age)\n",
    "\n",
    "\n",
    "# checking results\n",
    "df_got_translated['age'].isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56217f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing missing values for dob \n",
    "imputed_dob = df_got_translated['dateOfBirth'].median()\n",
    "df_got_translated['dateOfBirth'] = df_got_translated['dateOfBirth'].fillna(imputed_dob)\n",
    "\n",
    "\n",
    "# checking results\n",
    "df_got_translated['dateOfBirth'].isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089afb24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#trying to look into culture to understand the trend, analyse any duplicates and if possible to group the duplicates into one value\n",
    "df_got_translated['culture'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668db19e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "Analysing the cultures column to club the duplicates into one value:\n",
    "1. Same names - Northmen\n",
    "Northmen                   124\n",
    "northmen                     9\n",
    "2. Same category - Ironborn\n",
    "Ironborn                   112\n",
    "Ironmen                      5\n",
    "ironborn                     1\n",
    "3. same names = Free Folk\n",
    "Free Folk                   51\n",
    "Free folk                   11\n",
    "free folk                    1\n",
    "Wildling                     2\n",
    "First Men                    3\n",
    "Wildlings                    2\n",
    "4. Same = Qarth\n",
    "Qartheen                     6\n",
    "Qarth                        1\n",
    "5. Same = Braavosi\n",
    "Braavosi                    42\n",
    "Braavos                      1\n",
    "6. same = Ghiscari\n",
    "Ghiscari                    25\n",
    "Ghiscaricari                 1\n",
    "7. Same = Dornish\n",
    "Dornish                     25\n",
    "Dornishmen                  14\n",
    "Dothraki                    23\n",
    "Dorne                        2\n",
    "8. Same category = Riverlands\n",
    "Rivermen                    19\n",
    "Riverlands                   2\n",
    "9. Same category = Vale\n",
    "Valemen                     19\n",
    "Vale mountain clans         15\n",
    "Vale                         1\n",
    "10. Same = Meereen\n",
    "Meereen                      1\n",
    "Meereenese                   3\n",
    "11. Same = Reach\n",
    "Reach                       16\n",
    "Reachmen                     1\n",
    "The Reach                    1\n",
    "12. same = Westerman\n",
    "Westerman                    9\n",
    "Westermen                    4\n",
    "westermen                    2\n",
    "Westerlands                  2\n",
    "13. Same = Stormlander\n",
    "Stormlands                   7\n",
    "Stormlander                  1\n",
    "14. Same = Lysene\n",
    "Lysene                       4\n",
    "Lyseni                       3\n",
    "15. Same = Asshai\n",
    "Asshai                       2\n",
    "Asshai'i                     1\n",
    "16. Same = Summer Islanders\n",
    "Summer Islands               1\n",
    "Summer Islander              1\n",
    "Summer Isles                 5\n",
    "17. Same = Andals\n",
    "Andals                       1\n",
    "Andal                        1\n",
    "18. Same = Norvoshi\n",
    "Norvos                       1\n",
    "Norvoshi                     1\n",
    "19. Same = Lhazareen\n",
    "Lhazareen                    2\n",
    "Lhazarene                    1\n",
    "\n",
    "20. Others\n",
    "    Northern mountain clans      5\n",
    "    Crannogmen                   4\n",
    "    Astapori                     4\n",
    "    Pentoshi                     3\n",
    "    Myrish                       3\n",
    "    Sistermen                    2\n",
    "    Qohor                        2\n",
    "    Astapor                      1\n",
    "    Rhoynar                      1\n",
    "    Naathi                       1\n",
    "    Ibbenese                     1\n",
    "\n",
    "The below cultures will not be used in the part where we translate the culture column with one value for all duplicates.\n",
    "21. Tyroshi                      7\n",
    "22. Westeros                    12\n",
    "23. Valyrian                    43\n",
    "\n",
    "24. NAN = UNKNOWN\n",
    "\n",
    "Total of 34 different cultures, if grouped then 24, we will create or group the cultures to the above 24 different cultures so that we can create dummies for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cultures are translated into one for those with duplicate values \n",
    "all_cultures = {'Northmen': ['Northmen','northmen'],\n",
    "                'Ironborn': ['Ironborn','Ironmen','ironborn'],\n",
    "                'Freefolk': ['Free Folk','Free folk','free folk','Wildling','First Men','Wildlings'],\n",
    "                'Qarth': ['Qartheen','Qarth'],\n",
    "                'Braavosi': ['Braavosi','Braavos'],\n",
    "                'Ghiscari': ['Ghiscari', 'Ghiscaricari'],\n",
    "                'Dornish': ['Dornish','Dornishmen','Dorne'],\n",
    "                'Riverlands': ['Rivermen','Riverlands'],\n",
    "                'Vale': ['Valemen','Vale mountain clans','Vale'],\n",
    "                'Meereen': ['Meereen','Meereenese'],\n",
    "                'Reach': ['Reach','Reachmen','The Reach'],\n",
    "                'Westerman': ['Westerman','Westermen','westermen','Westerlands'],\n",
    "                'Stormlander':['Stormlands','Stormlander'],\n",
    "                'Lysene':['Lysene','Lyseni'],\n",
    "                'Asshai':['Asshai',\"Asshai'i\"],\n",
    "                'SummerIslanders': ['Summer Islands','Summer Islander','Summer Isles'],\n",
    "                'Andals':['Andals','Andal'],\n",
    "                'Norvoshi':['Norvos','Norvoshi'],\n",
    "                'Lhazareen':['Lhazareen','Lhazarene'],\n",
    "                'Others':['Northern mountain clans','Crannogmen','Astapori',\n",
    "                          'Pentoshi','Myrish','Sistermen','Qohor','Astapor',\n",
    "                          'Rhoynar','Naathi','Ibbenese']}\n",
    "\n",
    "#translating values and updating the same in dataframe\n",
    "\n",
    "for cultures in all_cultures:\n",
    "    df_got_translated.loc[df_got_translated.culture.isin(values=all_cultures[cultures]), 'culture'] = cultures\n",
    "\n",
    "df_got_translated['culture'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55927e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing missing values for title, culture, mother, father, heir and spouse with unknown\n",
    "df_got_translated['title']   = df_got_translated['title'].fillna('Unknown')\n",
    "\n",
    "df_got_translated['mother']  = df_got_translated['mother'].fillna('Unknown')\n",
    "\n",
    "df_got_translated['culture'] = df_got_translated['culture'].fillna('Unknown')\n",
    "\n",
    "df_got_translated['father']  = df_got_translated['father'].fillna('Unknown')\n",
    "\n",
    "df_got_translated['heir']    = df_got_translated['heir'].fillna('Unknown')\n",
    "\n",
    "df_got_translated['spouse']  = df_got_translated['spouse'].fillna('Unknown')\n",
    "\n",
    "# checking results\n",
    "df_got_translated.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c94ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing missing values for isAliveMother, isAliveFather, isAliveHeir, isAliveSpouse with 0\n",
    "\n",
    "fill = 0\n",
    "\n",
    "df_got_translated['isAliveMother']   = df_got_translated['isAliveMother'].fillna(fill)\n",
    "\n",
    "df_got_translated['isAliveFather'] = df_got_translated['isAliveFather'].fillna(fill)\n",
    "\n",
    "df_got_translated['isAliveHeir']  = df_got_translated['isAliveHeir'].fillna(fill)\n",
    "\n",
    "df_got_translated['isAliveSpouse']  = df_got_translated['isAliveSpouse'].fillna(fill)\n",
    "\n",
    "# checking results\n",
    "df_got_translated.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split_feature(col= 'name', \n",
    "                   df= df_got_translated, \n",
    "                   sep=' ', \n",
    "                   new_col_name='number_of_names')\n",
    "\n",
    "# checking results\n",
    "df_got_translated['number_of_names'].value_counts(normalize = False,\n",
    "                                        sort      = False,\n",
    "                                        ascending = False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a673ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding age and dob to feature engineer the available two continuous and interval features\n",
    "df_got_translated['age_dob'] = df_got_translated['age'] + df_got_translated['dateOfBirth']\n",
    "\n",
    "df_got_translated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing gender_guesser\n",
    "%pip install gender_guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debeded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: splitting name to get the lastname\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in df_got_translated.iterrows():\n",
    "    \n",
    "    # splitting name at ' '\n",
    "    split_name = df_got_translated.loc[index, 'name'].split(sep = ' ')\n",
    "\n",
    "    #Added this to reverse the order of words \n",
    "    surname = list(reversed(split_name))\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(surname)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "df_got_name = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# displaying the results\n",
    "df_got_name.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de79093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming column to concatenate\n",
    "df_got_name.columns = ['lastname' , 'middlename', 'firstname', 'value1', 'value2', 'value3']\n",
    "\n",
    "\n",
    "# concatenating personal_email_domain with friends DataFrame\n",
    "df_got_translated = pd.concat([df_got_translated, df_got_name['lastname']],\n",
    "                   axis = 1)\n",
    "\n",
    "\n",
    "# printing value counts of personal_email_domain\n",
    "df_got_translated.loc[: ,'lastname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30651cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for  index, value in df_got_translated.iterrows():\n",
    "    if \"Frey\" in df_got_translated.loc[index, 'name']:\n",
    "        df_got_translated.loc[index, 'house_new'] = 'House Frey'\n",
    "        \n",
    "    elif \"Stark\" in df_got_translated.loc[index, 'name']:\n",
    "        df_got_translated.loc[index, 'house_new'] = 'House Stark'\n",
    "    \n",
    "    elif \"Targaryen\" in df_got_translated.loc[index, 'name']:\n",
    "        df_got_translated.loc[index, 'house_new'] = 'House Targaryen'\n",
    "    \n",
    "    elif \"Lannister\" in df_got_translated.loc[index, 'name']:\n",
    "        df_got_translated.loc[index, 'house_new'] = 'House Lannister'\n",
    "    \n",
    "    elif \"Greyjoy\" in df_got_translated.loc[index, 'name']:\n",
    "        df_got_translated.loc[index, 'house_new'] = 'House Greyjoy'\n",
    "    \n",
    "    elif \"Tyrell\" in df_got_translated.loc[index, 'name']:\n",
    "        df_got_translated.loc[index, 'house_new'] = 'House Tyrell'\n",
    "    \n",
    "    elif \"Martell\" in df_got_translated.loc[index, 'name']:\n",
    "        df_got_translated.loc[index, 'house_new'] = 'House Martell'\n",
    "            \n",
    "    else:\n",
    "        df_got_translated.loc[index, 'house_new'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015abaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_got_translated[\"house\"].fillna(value=df_got_translated[\"house_new\"], inplace = True)\n",
    "df_got_translated['house_new'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d2b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing the missing values in house with house_new \n",
    "df_got_translated['house'] = df_got_translated['house'].fillna(df_got_translated['house_new'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee896a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new list for titles with just Known and Unknown to concat into the translated dataframe\n",
    "title = []\n",
    "    \n",
    "for titles in df_got_translated['title']:\n",
    "    if titles == 'Unknown':\n",
    "        title.append('title_unknown')\n",
    "\n",
    "    else:\n",
    "        title.append('title_known')\n",
    "\n",
    "#Converting the title list into a dataframe\n",
    "df_title = pd.DataFrame(title)\n",
    "df_title.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming column to concatenate\n",
    "df_title.columns = ['titles']\n",
    "\n",
    "\n",
    "# concatenating title with got translated DataFrame\n",
    "df_got_translated = pd.concat([df_got_translated, df_title['titles']],\n",
    "                   axis = 1)\n",
    "\n",
    "\n",
    "# printing value counts of title\n",
    "df_got_translated.loc[: ,'titles'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb57276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new list for house with just Known and Unknown to concat into the translated dataframe\n",
    "house = []\n",
    "\n",
    "#for loop to append values into the list \n",
    "for houses in df_got_translated['house']:\n",
    "    if houses == 'Unknown':\n",
    "        house.append('house_unknown')\n",
    "\n",
    "    else:\n",
    "        house.append('house_known')\n",
    "\n",
    "#Converting the title list into a dataframe\n",
    "df_house = pd.DataFrame(house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba58dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming column to concatenate\n",
    "df_house.columns = ['house_translated']\n",
    "\n",
    "\n",
    "# concatenating house with got translated DataFrame\n",
    "df_got_translated = pd.concat([df_got_translated, df_house['house_translated']],\n",
    "                   axis = 1)\n",
    "\n",
    "\n",
    "# printing value counts of title\n",
    "df_got_translated.loc[: ,'house_translated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting name to get the firstname and add first name column to got dataframe\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst2 = []\n",
    "\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in df_got_translated.iterrows():\n",
    "    \n",
    "    #splitting name at ' '\n",
    "    split_name = df_got_translated.loc[index, 'name'].split(sep = ' ')\n",
    "    \n",
    "    #appending placeholder_lst with the results\n",
    "    placeholder_lst2.append(split_name)\n",
    "    \n",
    "\n",
    "#converting placeholder_lst into a DataFrame \n",
    "df_got_firstname = pd.DataFrame(placeholder_lst2)\n",
    "\n",
    "\n",
    "#displaying the results\n",
    "df_got_firstname.head(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84097d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming column to concatenate\n",
    "df_got_firstname.columns = ['first_name' , 'middlename', 'lastname', 'value1', 'value2', 'value3']\n",
    "\n",
    "\n",
    "#concatenating firstname with got DataFrame\n",
    "df_got_translated = pd.concat([df_got_translated, df_got_firstname['first_name']],\n",
    "                   axis = 1)\n",
    "\n",
    "\n",
    "#printing value counts of firstname\n",
    "df_got_translated.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04078550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using gender guesser on firstname to guess the gender \n",
    "\n",
    "#placeholder list\n",
    "placeholder_lst3 = []\n",
    "\n",
    "\n",
    "#looping to guess gender\n",
    "for name in df_got_translated['first_name']:\n",
    "    guess = gender.Detector().get_gender(name)\n",
    "    print(guess)\n",
    "    placeholder_lst3.append(guess)\n",
    "\n",
    "\n",
    "#converting list into a series\n",
    "df_got_translated['gender_guess'] = pd.Series(placeholder_lst3)\n",
    "\n",
    "\n",
    "#checking results\n",
    "df_got_translated.head(n = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefdbe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using gender guesser output as a list to add as a column in the dataframe\n",
    "gender_guesses_list = ['unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'andy',\n",
    "'andy',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'female',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'male',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'mostly_female',\n",
    "'female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'andy',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown']\n",
    "\n",
    "#using the above list to create a \"Guessed_Gender\" column in the df_got_translated Dataset\n",
    "df_got_translated['Guessed_Gender'] = pd.Series(gender_guesses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding variables\n",
    "one_hot_titles       = pd.get_dummies(df_got_translated['titles'])\n",
    "one_hot_name         = pd.get_dummies(df_got_translated['number_of_names'])\n",
    "one_hot_culture      = pd.get_dummies(df_got_translated['culture'])\n",
    "one_hot_gender       = pd.get_dummies(df_got_translated['Guessed_Gender'])\n",
    "one_hot_houses       = pd.get_dummies(df_got_translated['house_translated'])\n",
    "\n",
    "\n",
    "\n",
    "#joining codings together\n",
    "df_got_translated = df_got_translated.join(other = [one_hot_titles, one_hot_name, one_hot_culture, one_hot_gender, one_hot_houses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5807c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking results\n",
    "df_got_translated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64373735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming all the columns after getting dummies\n",
    "df_got_translated.columns = ['S.No','name','title','culture','dateOfBirth','mother','father','heir',\n",
    "                             'house','spouse','book1_A_Game_Of_Thrones','book2_A_Clash_Of_Kings',\n",
    "                             'book3_A_Storm_Of_Swords','book4_A_Feast_For_Crows','book5_A_Dance_with_Dragons',\n",
    "                             'isAliveMother','isAliveFather','isAliveHeir','isAliveSpouse','isMarried','isNoble',\n",
    "                             'age','numDeadRelations','popularity','isAlive','m_title','m_culture','m_dateOfBirth',\n",
    "                             'm_mother','m_father','m_heir','m_house','m_spouse','m_isAliveMother','m_isAliveFather',\n",
    "                             'm_isAliveHeir','m_isAliveSpouse','m_age','number_of_names','age_dob','lastname','house_new',\n",
    "                             'titles','house_translated','first_name','Guessed_Gender','d_title_known','d_title_unknown',\n",
    "                             'd_numberofname_1','d_numberofname_2','d_numberofname_3','d_numberofname_4','d_numberofname_5',\n",
    "                             'd_numberofname_6','d_cul_Andals','d_cul_Asshai','d_cul_Braavosi','d_cul_Dornish','d_cul_Dothraki',\n",
    "                             'd_cul_Freefolk','d_cul_Ghiscari','d_cul_Ironborn','d_cul_Lhazareen','d_cul_Lysene','d_cul_Meereen',\n",
    "                             'd_cul_Northmen','d_cul_Norvoshi','d_cul_Others','d_cul_Qarth','d_cul_Reach','d_cul_Riverlands',\n",
    "                             'd_cul_Stormlander','d_cul_SummerIslanders','d_cul_Tyroshi','d_cul_Unknown','d_cul_Vale','d_cul_Valyrian',\n",
    "                             'd_cul_Westerman','d_cul_Westeros','d_gender_andy','d_gender_female','d_gender_male',\n",
    "                             'd_gender_mostly_female','d_gender_mostly_male','d_gender_unknown','d_house_known','d_house_unknown']\n",
    "\n",
    "\n",
    "#checking results\n",
    "df_got_translated.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede571c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping categorical variables after they've been encoded\n",
    "df_got_translated = df_got_translated.drop(['name','title','culture','mother','father',\n",
    "                                            'heir','house','spouse','house_new','lastname',\n",
    "                                            'titles','house_translated','first_name','Guessed_Gender'], axis = 1)\n",
    "\n",
    "\n",
    "#checking the results\n",
    "df_got_translated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46864d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(x_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "x_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the x data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        #optionally standardizing x_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(x_data)\n",
    "        x_scaled           = scaler.transform(x_data)\n",
    "        x_scaled_df        = pd.DataFrame(x_scaled)\n",
    "        x_data             = x_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    #train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    #creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    #setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        #building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        #recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        #recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    #optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        #plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    #returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    #visualizing the confusion matrix\n",
    "\n",
    "    #setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    #declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    #heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking correlation with isAlive\n",
    "df_got_corr = df_got_translated.corr(method= \"pearson\").round(decimals=2)\n",
    "\n",
    "df_got_corr['isAlive'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_got_translated.loc[: ,'isAlive'].value_counts(normalize = True).round(decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adcadce",
   "metadata": {},
   "source": [
    "<strong>Preparing Explanatory Variables</strong> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanatory variable isAlive is defined\n",
    "#x data\n",
    "got_data = df_got_translated.drop(['isAlive',\n",
    "                                  'book5_A_Dance_with_Dragons',\n",
    "                                  'isAliveMother',\n",
    "                                  'isAliveFather',\n",
    "                                  'isAliveHeir',\n",
    "                                  'isAliveSpouse',\n",
    "                                  'isMarried',\n",
    "                                  'isNoble',\n",
    "                                  'd_title_unknown',\n",
    "                                  'd_numberofname_6',\n",
    "                                  'd_cul_Others',\n",
    "                                  'd_gender_andy',\n",
    "                                  'd_house_unknown'],\n",
    "                                  axis = 1)\n",
    "\n",
    "\n",
    "#explanatory variable is being defined\n",
    "#y variable\n",
    "got_target = df_got_translated.loc[ : , 'isAlive' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = got_target) # preserving balance\n",
    "\n",
    "\n",
    "#merging training data for statsmodels\n",
    "got_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11f85e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b51c51",
   "metadata": {},
   "source": [
    "<strong>Univariate Logistic Model</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0bd769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_small = smf.logit(formula   = \"\"\"isAlive ~ age_dob\"\"\",\n",
    "                           data = got_train)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "results_logistic = logistic_small.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_logistic.summary2() # summary2() has AIC and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ad8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" isAlive ~ book1_A_Game_Of_Thrones + \n",
    "                                                 book2_A_Clash_Of_Kings + \n",
    "                                                 book3_A_Storm_Of_Swords + \n",
    "                                                 book4_A_Feast_For_Crows + \n",
    "                                                 numDeadRelations + \n",
    "                                                 popularity + \n",
    "                                                 age_dob + \n",
    "                                                 d_gender_female + \n",
    "                                                 d_gender_male + \n",
    "                                                 d_gender_mostly_female + \n",
    "                                                 d_gender_mostly_male + \n",
    "                                                 d_house_known \"\"\",\n",
    "                                        data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c3e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" isAlive ~ book1_A_Game_Of_Thrones + \n",
    "                                                  book2_A_Clash_Of_Kings + \n",
    "                                                  book3_A_Storm_Of_Swords + \n",
    "                                                  book4_A_Feast_For_Crows + \n",
    "                                                  popularity + \n",
    "                                                  age_dob \"\"\",\n",
    "                                        data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model object with all significant features\n",
    "logit_sig = smf.logit(formula = \"\"\" isAlive ~ book1_A_Game_Of_Thrones + \n",
    "                                              book2_A_Clash_Of_Kings + \n",
    "                                              book4_A_Feast_For_Crows + \n",
    "                                              popularity + \n",
    "                                              age_dob\"\"\",\n",
    "                                            data    = got_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "logit_sig = logit_sig.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "logit_sig.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b481d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanatory sets from last session\n",
    "\n",
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['book1_A_Game_Of_Thrones','book2_A_Clash_Of_Kings','book3_A_Storm_Of_Swords',\n",
    "                   'book4_A_Feast_For_Crows','numDeadRelations','popularity','age_dob','d_gender_andy',\n",
    "                   'd_gender_female','d_gender_male','d_gender_mostly_female','d_gender_mostly_male',\n",
    "                   'd_house_known'],\n",
    " \n",
    "\n",
    " # significant variables only (set 1)\n",
    " 'logit_sig'    : ['book1_A_Game_Of_Thrones','book2_A_Clash_Of_Kings','book4_A_Feast_For_Crows',\n",
    "                   'popularity','age_dob']\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04824797",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# printing candidate variable sets\n",
    "print(f\"\"\"\n",
    "/--------------------------\\\\\n",
    "|Explanatory Variable Sets |\n",
    "\\\\--------------------------/\n",
    "\n",
    "Full Model:\n",
    "-----------\n",
    "{candidate_dict['logit_full']}\n",
    "\n",
    "\n",
    "Significant p-value Model:\n",
    "--------------------------------\n",
    "{candidate_dict['logit_sig']}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the full model\n",
    "got_data   =  df_got_translated.loc[ : , candidate_dict['logit_sig']]\n",
    "got_target =  df_got_translated.loc[ : , 'isAlive']\n",
    "\n",
    "\n",
    "# This is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            got_data,\n",
    "            got_target,\n",
    "            test_size    = 0.10,\n",
    "            random_state = 219,\n",
    "            stratify     = got_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix\n",
    "print(confusion_matrix(y_true = y_test,\n",
    "                       y_pred = logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6405857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the visual_cm function\n",
    "visual_cm(true_y = y_test,\n",
    "          pred_y = logreg_pred,\n",
    "          labels = ['Alive', 'Not Alive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476096e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "logreg_model_values = zip(df_got_translated[candidate_dict['logit_sig']].columns,\n",
    "                          logreg_fit.coef_.ravel().round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "logreg_model_lst = [('intercept', logreg_fit.intercept_[0].round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in logreg_model_values:\n",
    "    logreg_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in logreg_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57712d36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<strong>Classification Trees (CART Models)</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8177733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e42770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1053927",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "#plt.figure(figsize=(150,50))\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "#plot_tree(decision_tree = full_tree_fit, \n",
    "#          feature_names = df_got_translated.columns,\n",
    "#          filled        = True, \n",
    "#          rounded       = True, \n",
    "#          fontsize      = 14)\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b12ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "tree_pruned = DecisionTreeClassifier(max_depth        = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state     = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit = tree_pruned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4) # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting figure size\n",
    "plt.figure(figsize=(20, 10)) # adjusting to better fit the visual\n",
    "\n",
    "\n",
    "# developing a plotted tree\n",
    "plot_tree(decision_tree = pruned_tree_fit, # changing to pruned_tree_fit\n",
    "          feature_names = df_got_translated.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 14)\n",
    "\n",
    "\n",
    "# rendering the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca035fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(pruned_tree_fit,\n",
    "                         train = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing results\n",
    "print(f\"\"\"\n",
    "Model         AUC Score      TN, FP, FN, TP\n",
    "-----         ---------      --------------\n",
    "Logistic      {logreg_auc_score}         {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "Full Tree     {full_tree_auc_score}         {full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp}\n",
    "Pruned Tree   {pruned_tree_auc_score}           {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Full Tree', 'Pruned Tree'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, full_tree_auc_score, pruned_tree_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "model_performance.to_excel('../path_practice/__results/classification_model_performance_got.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b7b69",
   "metadata": {},
   "source": [
    "<strong>Classification modeling with KNN</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(x_data        = got_data,\n",
    "                                  y_data        = got_target,\n",
    "                                  response_type = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eed7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(got_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(got_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            got_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.10,\n",
    "            stratify     = got_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca34c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the visual_cm function\n",
    "visual_cm(true_y = y_test,\n",
    "          pred_y = knn_pred,\n",
    "          labels = ['Alive', 'Not Alive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ca341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tree_tn, \\\n",
    "knn_tree_fp, \\\n",
    "knn_tree_fn, \\\n",
    "knn_tree_tp = confusion_matrix(y_true = y_test, y_pred = knn_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {knn_tree_tn}\n",
    "False Positives: {knn_tree_fp}\n",
    "False Negatives: {knn_tree_fn}\n",
    "True Positives : {knn_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b87e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90f62e",
   "metadata": {},
   "source": [
    "<strong>Logistic Regression with Hyperparameter tuning</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af8b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a logistic regression model with default values\n",
    "lr_default = LogisticRegression(solver = 'lbfgs',\n",
    "                                C = 1.0,\n",
    "                                warm_start = False,\n",
    "                                random_state = 219)\n",
    "#warm start lets this algorith learn from previous algorithms, its false by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058bd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "lr_default_fit = lr_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_default_pred = lr_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', lr_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', lr_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# SCORING with AUC\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_default_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = lr_default_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = lr_default_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = lr_default_pred).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba6baa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<strong>Hyperparameter tuning with RandomizedSearchCV</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10155d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# RandomizedSearchCV\n",
    "########################################\n",
    "\n",
    "#declaring a hyperparameter space\n",
    "C_range          = np.arange(0.1, 5.0, 0.1)\n",
    "warm_start_range = [True, False]\n",
    "solver_range     = ['newton-cg', 'sag', 'lbfgs']\n",
    "\n",
    "\n",
    "#creating a hyperparameter grid\n",
    "param_grid = {'C'          : C_range,\n",
    "              'warm_start' : warm_start_range,\n",
    "              'solver'     : solver_range}\n",
    "\n",
    "\n",
    "#instantiating the model object without hyperparameters\n",
    "lr_tuned = LogisticRegression(random_state = 219,\n",
    "                              max_iter     = 1000) # increased for convergence\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "                                 param_distributions = param_grid, # parameters to tune\n",
    "                                 cv                  = 3,          # how many folds in cross-validation\n",
    "                                 n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "                                 random_state        = 219,        # starting point for random sequence\n",
    "                                 scoring = make_scorer(\n",
    "                                           roc_auc_score,\n",
    "                                           needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "#fitting to the FULL DATASET (due to cross-validation)\n",
    "lr_tuned_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the results of RandomizedSearch CV\n",
    "lr_tuned_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c32135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the best estimator for the model\n",
    "lr_tuned_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a model based on hyperparameter tuning results\n",
    "\n",
    "#instantiating a logistic regression model with tuned values\n",
    "lr_tuned = LogisticRegression(C            = 3.9000000000000004,\n",
    "                              warm_start   = True,\n",
    "                              solver       = 'newton-cg',\n",
    "                              max_iter     = 1000,\n",
    "                              random_state = 219)\n",
    "\n",
    "\n",
    "#fitting the model\n",
    "lr_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "#predicting based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "#scoring the results\n",
    "print('Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "#saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "#saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c842504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "#printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd82626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model performance\n",
    "model_performance = pd.read_excel('../path_practice/__results/classification_model_performance_got.xlsx')\n",
    "\n",
    "\n",
    "#declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(x_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(x_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "#appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned LR',\n",
    "                           'Training Accuracy' : lr_train_acc,\n",
    "                           'Testing Accuracy'  : lr_test_acc,\n",
    "                           'AUC Score'         : lr_auc,\n",
    "                           'Confusion Matrix'  : (lr_tuned_tn,\n",
    "                                                  lr_tuned_fp,\n",
    "                                                  lr_tuned_fn,\n",
    "                                                  lr_tuned_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "#checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b362550",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<strong>Hyperparameter tuning on classification trees</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring a hyperparameter space\n",
    "criterion_range = ['gini', 'entropy']\n",
    "splitter_range  = ['best', 'random']\n",
    "depth_range     = np.arange(1, 25, 1)\n",
    "leaf_range      = np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "#creating a hyperparameter grid\n",
    "param_grid = {'criterion'        : criterion_range,\n",
    "              'splitter'         : splitter_range,\n",
    "              'max_depth'        : depth_range,\n",
    "              'min_samples_leaf' : leaf_range}\n",
    "\n",
    "\n",
    "#instantiating the model object without hyperparameters\n",
    "tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "#RandomizedSearchCV object\n",
    "tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "                                   param_distributions   = param_grid,\n",
    "                                   cv                    = 3,\n",
    "                                   n_iter                = 1000,\n",
    "                                   random_state          = 219,\n",
    "                                   scoring = make_scorer(roc_auc_score,\n",
    "                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "#fitting to the FULL DATASET (due to cross-validation)\n",
    "tuned_tree_cv.fit(got_data, got_target)\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db17f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a model based on hyperparameter tuning results as above\n",
    "\n",
    "#instantiating a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(splitter         = 'best',\n",
    "                                    min_samples_leaf = 4,\n",
    "                                    max_depth        = 17,\n",
    "                                    criterion        = 'entropy',\n",
    "                                    random_state     = 219)\n",
    "\n",
    "\n",
    "#fitting to the FULL DATASET (due to cross-validation)\n",
    "tree_tuned_fit = tree_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "#predicting based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "#scoring the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "#saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "#saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                       y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834340be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "#printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(x_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(x_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "#appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned Tree',\n",
    "                           'Training Accuracy' : tree_train_acc,\n",
    "                           'Testing Accuracy'  : tree_test_acc,\n",
    "                           'AUC Score'         : tree_auc,\n",
    "                           'Confusion Matrix'  : (tuned_tree_tn,\n",
    "                                                  tuned_tree_fp,\n",
    "                                                  tuned_tree_fn,\n",
    "                                                  tuned_tree_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "#checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf12b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting figure size\n",
    "plt.figure(figsize=(40, 10))\n",
    "\n",
    "\n",
    "#developing a plotted tree\n",
    "plot_tree(decision_tree = tree_tuned_fit, \n",
    "          feature_names = df_got_translated.columns,\n",
    "          filled        = True, \n",
    "          rounded       = True, \n",
    "          fontsize      = 14)\n",
    "\n",
    "\n",
    "#rendering the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff59bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the DataFrame to Excel\n",
    "model_performance.to_excel('../path_practice/__results/classification_model_performance_got.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new tools\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading model performance\n",
    "model_performance = pd.read_excel('../path_practice/__results/classification_model_performance_got.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8792a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    #declaring the number\n",
    "    n_features = train.shape[1]\n",
    "    \n",
    "    #setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('../path_practice/__results/Feature_Importance_got.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c8a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split with the logit_sig variables\n",
    "got_data   =  df_got_translated.loc[ : , candidate_dict['logit_full'] ]\n",
    "got_target =  df_got_translated.loc[ : , 'isAlive' ]\n",
    "\n",
    "\n",
    "#train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                    got_data,\n",
    "                                                    got_target,\n",
    "                                                    random_state = 219,\n",
    "                                                    test_size    = 0.10,\n",
    "                                                    stratify     = got_target\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5c8bc",
   "metadata": {},
   "source": [
    "<strong>Random Forest</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = \"gini\",\n",
    "                                    max_depth        = 4,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ebcb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#predicting based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "#scoring the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "#saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76569084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting feature importances\n",
    "plot_feature_importances(rf_default_fit, x_train, export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "#printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring model performance objects\n",
    "rf_train_acc = rf_default_fit.score(x_train, y_train).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(x_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "#appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Random Forest (Full)',\n",
    "                           'Training Accuracy'  : rf_train_acc,\n",
    "                           'Testing Accuracy'   : rf_test_acc,\n",
    "                           'AUC Score'          : rf_auc,\n",
    "                           'Confusion Matrix'   : (rf_tn,\n",
    "                                                   rf_fp,\n",
    "                                                   rf_fn,\n",
    "                                                   rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "#checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820134db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#predicting based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "#declaring a hyperparameter space\n",
    "estimator_range  = np.arange(100, 1100, 250)\n",
    "leaf_range       = np.arange(1, 31, 10)\n",
    "criterion_range  = ['gini', 'entropy']\n",
    "bootstrap_range  = [True, False]\n",
    "warm_start_range = [True, False]\n",
    "\n",
    "\n",
    "#creating a hyperparameter grid\n",
    "param_grid = {'n_estimators'     : estimator_range,\n",
    "              'min_samples_leaf' : leaf_range,\n",
    "              'criterion'        : criterion_range,\n",
    "              'bootstrap'        : bootstrap_range,\n",
    "              'warm_start'       : warm_start_range}\n",
    "\n",
    "\n",
    "#instantiating the model object without hyperparameters\n",
    "forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "                               param_distributions = param_grid,\n",
    "                               cv         = 3,\n",
    "                               n_iter     = 1000,\n",
    "                               scoring    = make_scorer(roc_auc_score,\n",
    "                                            needs_threshold = False))\n",
    "\n",
    "\n",
    "#fitting to the FULL DATASET (due to cross-validation)\n",
    "forest_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "#predict step is not needed\n",
    "\n",
    "\n",
    "#printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best estimators based on RandomizedSearchCV\n",
    "forest_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a model based on hyperparameter tuning results\n",
    "\n",
    "#instantiating with best_estimator\n",
    "forest_tuned = RandomForestClassifier(criterion='gini', \n",
    "                                      min_samples_leaf=1,\n",
    "                                      n_estimators=350, \n",
    "                                      random_state=219, \n",
    "                                      warm_start=True)\n",
    "\n",
    "\n",
    "#fitting to the FULL DATASET (due to cross-validation)\n",
    "forest_tuned_fit = forest_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "#predicting based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "#scoring the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                       y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "#saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "#saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting feature importances\n",
    "plot_feature_importances(forest_tuned_fit,\n",
    "                         train = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "#printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23818f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring model performance objects\n",
    "tuned_rf_train_acc = forest_tuned_fit.score(x_train, y_train).round(4)\n",
    "tuned_rf_test_acc  = forest_tuned_fit.score(x_test, y_test).round(4)\n",
    "tuned_rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                   y_score = forest_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "#appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Tuned Random Forest (Full)',\n",
    "                           'Training Accuracy'  : tuned_rf_train_acc,\n",
    "                           'Testing Accuracy'   : tuned_rf_test_acc,\n",
    "                           'AUC Score'          : tuned_rf_auc,\n",
    "                           'Confusion Matrix'   : (tuned_rf_tn,\n",
    "                                                   tuned_rf_fp,\n",
    "                                                   tuned_rf_fn,\n",
    "                                                   tuned_rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "#checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c73b04",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<strong>Gradient Boost Machines (GBM)</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadecf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "#fit step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#predicting based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "#scoring the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "#printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoring the model\n",
    "gbm_train_acc = full_gbm_default_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "\n",
    "#appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (Full)',\n",
    "                          'Training Accuracy' : gbm_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_test_acc,\n",
    "                          'AUC Score'         : gbm_auc,\n",
    "                          'Confusion Matrix'  : (gbm_default_tn,\n",
    "                                                 gbm_default_fp,\n",
    "                                                 gbm_default_fn,\n",
    "                                                 gbm_default_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "#checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ba8c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Below code is frozen and commented as it takes long to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring a hyperparameter space\n",
    "learn_range        = np.arange(0.1,2.2,0.5)\n",
    "estimator_range    = np.arange(100, 501, 25)\n",
    "depth_range        = np.arange(2, 11, 2)\n",
    "warm_start_range = [True, False]\n",
    "\n",
    "\n",
    "#creating a hyperparameter grid\n",
    "param_grid = {'learning_rate' : learn_range,\n",
    "              'max_depth'     : depth_range,\n",
    "              'n_estimators'  : estimator_range,\n",
    "              'warm_start'    : warm_start_range}\n",
    "\n",
    "#instantiating the model object without hyperparameters\n",
    "full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "#GridSearchCV object\n",
    "full_gbm_cv = RandomizedSearchCV(estimator           = full_gbm_grid,\n",
    "                                 param_distributions = param_grid,\n",
    "                                 cv                  = 3,\n",
    "                                 n_iter              = 500,\n",
    "                                 random_state        = 219,\n",
    "                                 scoring             = make_scorer(roc_auc_score,\n",
    "                                                       needs_threshold = False))\n",
    "\n",
    "\n",
    "#fitting to the FULL DATASET (due to cross-validation)\n",
    "full_gbm_cv.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "#predict step is not needed\n",
    "\n",
    "\n",
    "#printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ac411",
   "metadata": {},
   "source": [
    "Tuned Parameters  : {'warm_start': False, 'n_estimators': 375, 'max_depth': 2, 'learning_rate': 1.1}\n",
    "Tuned Training AUC: 0.7551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74662f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating with best_estimator\n",
    "gbm_tuned = GradientBoostingClassifier(learning_rate = 1.1,\n",
    "                                       max_depth     = 2,\n",
    "                                       n_estimators  = 375,\n",
    "                                       warm_start    = False,\n",
    "                                       random_state  = 219)\n",
    "\n",
    "\n",
    "#fitting to the FULL DATASET (due to cross-validation)\n",
    "gbm_tuned_fit = gbm_tuned.fit(got_data, got_target)\n",
    "\n",
    "\n",
    "#predicting based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "#scoring the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9536f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "#printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ef172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "#appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : '**Final Model - Tuned GBM**',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Score'          : gbm_auc,\n",
    "                          'Confusion Matrix'   : (gbm_tuned_tn,\n",
    "                                                  gbm_tuned_fp,\n",
    "                                                  gbm_tuned_fn,\n",
    "                                                  gbm_tuned_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "#checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the DataFrame to Excel\n",
    "model_performance.to_excel('../path_practice/__results/classification_model_performance_got.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing results\n",
    "\n",
    "print(f\"\"\"\n",
    "     Model          AUC        Training     Testing       Confusion Matrix\n",
    "                   Score       Accuracy     Accuracy      (TN, FP, FN, TP)\n",
    "--------------   ----------   ----------   ----------   --------------------\n",
    "1. Logistic        {model_performance['AUC Score'][0]}       {model_performance['Training Accuracy'][0]}       {model_performance['Testing Accuracy'][0]}        {model_performance['Confusion Matrix'][0]}\n",
    "2. Full Tree       {model_performance['AUC Score'][1]}       {model_performance['Training Accuracy'][1]}       {model_performance['Testing Accuracy'][1]}       {model_performance['Confusion Matrix'][1]}\n",
    "2. Pruned Tree     {model_performance['AUC Score'][2]}         {model_performance['Training Accuracy'][2]}        {model_performance['Testing Accuracy'][2]}       {model_performance['Confusion Matrix'][2]}\n",
    "3. Tuned LR        {model_performance['AUC Score'][3]}       {model_performance['Training Accuracy'][3]}       {model_performance['Testing Accuracy'][3]}        {model_performance['Confusion Matrix'][3]}\n",
    "4. Tuned Tree      {model_performance['AUC Score'][4]}       {model_performance['Training Accuracy'][4]}       {model_performance['Testing Accuracy'][4]}       {model_performance['Confusion Matrix'][4]}\n",
    "5. Random Forest   {model_performance['AUC Score'][5]}         {model_performance['Training Accuracy'][5]}       {model_performance['Testing Accuracy'][5]}       {model_performance['Confusion Matrix'][5]}\n",
    "   (Full)\n",
    "6. Tuned Random    {model_performance['AUC Score'][6]}       {model_performance['Training Accuracy'][6]}       {model_performance['Testing Accuracy'][6]}       {model_performance['Confusion Matrix'][6]}\n",
    "   Forest (Full)\n",
    "7. GBM (Full)      {model_performance['AUC Score'][7]}       {model_performance['Training Accuracy'][7]}       {model_performance['Testing Accuracy'][7]}       {model_performance['Confusion Matrix'][7]}\n",
    "8. *Tuned GBM*     {model_performance['AUC Score'][8]}       {model_performance['Training Accuracy'][8]}       {model_performance['Testing Accuracy'][8]}       {model_performance['Confusion Matrix'][8]}\n",
    "   Final Model\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"Tuned GBM is my final model with a test train gap of 0.0305 and an AUC Score of {gbm_auc}.\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
