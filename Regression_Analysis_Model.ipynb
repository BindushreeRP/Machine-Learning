{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b91e7e9",
   "metadata": {},
   "source": [
    "<h2> A1: Regression Model Development</h2>\n",
    "<h3> ~ Bindushree R P</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8abc357",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the steps below, we import all the packages and create models to predict Birth Weight with the best suitable variables.\n",
    "The variables were split into continuous, interval/count and categorical as specified below:\n",
    "<br>\n",
    "Continuous variables: mage, meduc, fage, feduc, cigs, drink\n",
    "<br>\n",
    "Count/Interval variables: npvis, monpre\n",
    "<br>\n",
    "Categorical variables: male, mwhte, mblck, moth, fwhte, fblck, foth\n",
    "<br>\n",
    "Target Variable: bwght\n",
    "<br>\n",
    "All the models were developed and the best model was marked with the asteric in the final model comparison output.\n",
    "<br>\n",
    "Source: Used regression model code from the classroom scripts 3 and 4.\n",
    "<br>\n",
    "Final model and result: Final model was selected based on the highest test score and less than 0.05 difference. \n",
    "The final results were displayed in the form of a dynamic string at the end of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the needed libraries: data science, graphical output, mathematical essentials and regression modeling\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import statsmodels.formula.api as smf \n",
    "\n",
    "\n",
    "#setting print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#loading the file\n",
    "file = \"./__datasets/birthweight_low_A1.xlsx\"\n",
    "\n",
    "\n",
    "#reading the file \n",
    "df_birthweight = pd.read_excel(io  = file,\n",
    "                               sheet_name = 0,\n",
    "                               header     = 0)\n",
    "\n",
    "\n",
    "#outputting the first ten rows of the dataset\n",
    "df_birthweight.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the information of the dataframe to check the datatypes and number of total columns\n",
    "df_birthweight.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236df819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at the number of missing values\n",
    "df_birthweight.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b57c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list with continuous data\n",
    "continuous_data = ['bwght','mage','meduc','fage','feduc','cigs','drink','male']\n",
    "\n",
    "#developing a correlation matrix based on the list: continuous_data\n",
    "df_birthweight_corr = df_birthweight[continuous_data].corr(method=\"pearson\")\n",
    "\n",
    "#filtering the results to only show the correlation of the continuous data with birth weight\n",
    "df_birthweight_corr.loc[ : , \"bwght\"].round(decimals = 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining and instantiating a model object for regression\n",
    "lm_best = smf.ols(formula = \"\"\"bwght ~ fage + mage + cigs + drink + male\n",
    "                               + feduc + meduc\"\"\",\n",
    "                  data = df_birthweight)\n",
    "\n",
    "\n",
    "#fitting the data into the model\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "#analysing the summary output\n",
    "print(results.summary())\n",
    "\n",
    "#From this output, it can be seen that the p values for mothers education, fathers education and baby being male \n",
    "#are very high. We shall try to feature engineer some variables and check how the R square and P values vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ffbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a copy of the data frame to translate and impute missing values going forward\n",
    "df_birthweight_translated = pd.DataFrame.copy(df_birthweight)\n",
    "\n",
    "#checking for the number of missing values in our translated file\n",
    "df_birthweight_translated.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f767f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping to detect features with missing values\n",
    "for col in df_birthweight_translated:\n",
    "\n",
    "    # creating columns for missing valued columns and imputing with 1s if missing and 0 if not\n",
    "    if df_birthweight_translated[col].isnull().astype(int).sum() > 0:\n",
    "        df_birthweight_translated['m_'+col] = df_birthweight_translated[col].isnull().astype(int)\n",
    "\n",
    "# summing the missing value flags to check the results of the loop above\n",
    "df_birthweight_translated[    ['m_meduc', 'm_npvis','m_feduc']    ].sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing the missing values with median for meduc, npvis and feduc\n",
    "\n",
    "for col in df_birthweight_translated.columns:\n",
    "    fill = df_birthweight_translated.median()\n",
    "    df_birthweight_translated.fillna(value = fill,\n",
    "                                    inplace = True)\n",
    "\n",
    "#df_birthweight_translated.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d67a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATE a model object\n",
    "lm_best = smf.ols(formula = \"\"\"bwght ~ fage + mage + cigs + drink + meduc + feduc \n",
    "                               + m_meduc + m_feduc + male + npvis + m_npvis\"\"\",\n",
    "                  data = df_birthweight_translated)\n",
    "\n",
    "\n",
    "#FIT the data into the model object\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "#analyze the SUMMARY output\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028192c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the results of correlation of all continuous variables with birthweight\n",
    "\n",
    "continuous_data = ['bwght', 'mage','meduc','fage','feduc','cigs','drink']\n",
    "\n",
    "df_birthweight_corr = df_birthweight_translated[continuous_data].corr(method = 'pearson')\n",
    "df_birthweight_corr.loc[ : , \"bwght\"].round(decimals = 2).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d076bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transforming variables and saving it to the dataset as columns\n",
    "df_birthweight_translated['log_bwght'] = np.log(df_birthweight_translated['bwght'])\n",
    "df_birthweight_translated['log_mage'] = np.log(df_birthweight_translated['mage'])\n",
    "df_birthweight_translated['mage_multiply_fage'] = df_birthweight_translated['mage'] * df_birthweight_translated['fage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the correlation with the log transformed variables\n",
    "#INSTANTIATE a model object\n",
    "lm_best = smf.ols(formula = \"\"\"log_bwght ~ fage + cigs + drink + meduc + feduc + \n",
    "                               mblck + fblck + male + m_npvis + mage_multiply_fage\"\"\",\n",
    "                  data = df_birthweight_translated)\n",
    "\n",
    "\n",
    "#FIT the data into the model object\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "#analyze the SUMMARY output\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the stats model and scikit packages needed\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data with explanatory columns by dropping other columns\n",
    "birthweight_data   = df_birthweight_translated.drop([\"bwght\",\n",
    "                                                     \"log_bwght\",\n",
    "                                                     \"omaps\",\n",
    "                                                     \"fmaps\",\n",
    "                                                     \"log_mage\",\n",
    "                                                     \"mage_multiply_fage\"],\n",
    "                                                      axis = 1)\n",
    "\n",
    "\n",
    "#Creating target variables for regression\n",
    "birthweight_target = df_birthweight_translated.loc[ : , \"bwght\"]\n",
    "log_birthweight_target = df_birthweight_translated.loc[ : , \"log_bwght\"]\n",
    "\n",
    "\n",
    "#training and testing sets with test size of 0.25 and random state of 219\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            birthweight_data,\n",
    "            birthweight_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "#checking the shapes of the datasets\n",
    "print(f\"\"\"\n",
    "Training Data\n",
    "-------------\n",
    "X-side: {x_train.shape}\n",
    "y-side: {y_train.shape}\n",
    "\n",
    "\n",
    "Testing Data\n",
    "------------\n",
    "X-side: {x_test.shape}\n",
    "y-side: {y_test.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ef2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring set of x-variables\n",
    "x_variables = ['meduc', 'drink', 'cigs', 'fage']\n",
    "\n",
    "\n",
    "# looping to make x-variables suitable for statsmodels\n",
    "for val in x_variables:\n",
    "    print(f\"{val} +\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05682ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging X_train and y_train to use in all the stats models\n",
    "birthweight_train = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "\n",
    "#building the model\n",
    "lm_best = smf.ols(formula =  \"\"\"bwght ~ meduc +\n",
    "                                        drink +\n",
    "                                        cigs +\n",
    "                                        fage\"\"\",\n",
    "                                data = birthweight_train)\n",
    "\n",
    "\n",
    "#fitting the model based on our data\n",
    "results = lm_best.fit()\n",
    "\n",
    "\n",
    "\n",
    "#analyzing the summary output\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying modelin scikit-learn\n",
    "\n",
    "#preparing ols model to use the x-variables defined earlier\n",
    "ols_data = df_birthweight_translated.loc[ : , x_variables]\n",
    "\n",
    "\n",
    "#preparing the response data for the model\n",
    "birthweight_target = df_birthweight_translated.loc[ : , \"bwght\"]\n",
    "\n",
    "\n",
    "#Creating two train test split sets for using in the models\n",
    "#all variables data is used to create FULL train test split \n",
    "x_train_FULL, x_test_FULL, y_train_FULL, y_test_FULL = train_test_split(\n",
    "            birthweight_data,     \n",
    "            birthweight_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "#only x-variables defined withing OLS data to build OLS test train split\n",
    "x_train_OLS, x_test_OLS, y_train_OLS, y_test_OLS = train_test_split(\n",
    "            ols_data,\n",
    "            birthweight_target, \n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc68e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model object is instantiated\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "#fitting the model to training data\n",
    "lr_fit = lr.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "#predicting on new dataset\n",
    "lr_pred = lr_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "#scoring the results to get the R square for test and train\n",
    "print('OLS Training Score :', lr.score(x_train_OLS, y_train_OLS).round(4))\n",
    "print('OLS Testing Score  :',  lr.score(x_test_OLS, y_test_OLS).round(4))\n",
    "\n",
    "lr_train_score = lr.score(x_train_OLS, y_train_OLS).round(4)\n",
    "lr_test_score  = lr.score(x_test_OLS, y_test_OLS).round(4)\n",
    "\n",
    "#displaying and saving the gap between training and testing\n",
    "print('OLS Train-Test Gap :', abs(lr_train_score - lr_test_score).round(4))\n",
    "lr_test_gap = abs(lr_train_score - lr_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d366bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature name is zipped into its coefficient \n",
    "lr_model_values = zip(birthweight_data[x_variables].columns,\n",
    "                      lr_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "#storing model features in a placeholder list\n",
    "lr_model_lst = [('intercept', lr_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "#printing the feature coefficient pair\n",
    "for val in lr_model_values:\n",
    "    lr_model_lst.append(val)\n",
    "    \n",
    "\n",
    "#printing the results along with the coefficient name\n",
    "for pair in lr_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec35ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model object is instantiated\n",
    "lasso_model = sklearn.linear_model.Lasso(alpha = 1.0,\n",
    "                                         normalize = True) # default magitude\n",
    "\n",
    "\n",
    "#fitting the model to training data\n",
    "lasso_fit = lasso_model.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "#predicting on new dataset\n",
    "lasso_pred = lasso_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "#scoring the results to get the R square for test and train\n",
    "print('Lasso Training Score :', lasso_model.score(x_train_OLS, y_train_OLS).round(4))\n",
    "print('Lasso Testing Score  :', lasso_model.score(x_test_OLS, y_test_OLS).round(4))\n",
    "\n",
    "\n",
    "#using the below code given by Prof. Chase to save the scores and print the resulting train and test model scores\n",
    "\n",
    "# saving scoring data for future use\n",
    "lasso_train_score = lasso_model.score(x_train_OLS, y_train_OLS).round(4)\n",
    "lasso_test_score  = lasso_model.score(x_test_OLS, y_test_OLS).round(4)\n",
    "\n",
    "\n",
    "#displaying and saving the gap between training and testing\n",
    "print('Lasso Train-Test Gap :', abs(lasso_train_score - lasso_test_score).round(4))\n",
    "lasso_test_gap = abs(lasso_train_score - lasso_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb482fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature name is zipped into its coefficient along with the used data for this model\n",
    "lasso_model_values = zip(ols_data, lasso_fit.coef_.round(decimals = 2))\n",
    "\n",
    "#storing model features in a placeholder list\n",
    "lasso_model_lst = [('intercept', lasso_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "#printing the feature coefficient pair\n",
    "for val in lasso_model_values:\n",
    "    lasso_model_lst.append(val)\n",
    "    \n",
    "#printing the results along with the coefficient name\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c7f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the feature coefficient pair\n",
    "for feature, coefficient in lasso_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            lasso_model_lst.remove((feature, coefficient))\n",
    "\n",
    "#printing the results along with the coefficient name\n",
    "for pair in lasso_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e848b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model object is instantiated\n",
    "ard_model = sklearn.linear_model.ARDRegression()\n",
    "\n",
    "\n",
    "#fitting the model to training data\n",
    "ard_fit = ard_model.fit(x_train_OLS,y_train_OLS)\n",
    "\n",
    "\n",
    "#predicting on new dataset\n",
    "ard_pred = ard_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "print('Training Score:', ard_model.score(x_train_OLS, y_train_OLS).round(4))\n",
    "print('Testing Score :', ard_model.score(x_test_OLS, y_test_OLS).round(4))\n",
    "\n",
    "\n",
    "#saving scoring data for future use\n",
    "ard_train_score = ard_model.score(x_train_OLS, y_train_OLS).round(4)\n",
    "ard_test_score  = ard_model.score(x_test_OLS, y_test_OLS).round(4)\n",
    "\n",
    "\n",
    "#displaying and saving the gap between training and testing\n",
    "print('ARD Train-Test Gap :', abs(ard_train_score - ard_test_score).round(4))\n",
    "ard_test_gap = abs(ard_train_score - ard_test_score).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature name is zipped into its coefficient along with the used data for this model\n",
    "ard_model_values = zip(birthweight_data[x_variables], ard_fit.coef_.round(decimals = 5))\n",
    "\n",
    "#storing model features in a placeholder list\n",
    "ard_model_lst = [('intercept', ard_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "#printing the feature coefficient pair\n",
    "for val in ard_model_values:\n",
    "    ard_model_lst.append(val)\n",
    "    \n",
    "\n",
    "#printing the results along with the coefficient name\n",
    "for pair in ard_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e3efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: Prof.Chase' classroom script\n",
    "#dropping coefficients that are equal to zero\n",
    "\n",
    "#printing out each feature-coefficient pair one by one\n",
    "for feature, coefficient in ard_model_lst:\n",
    "        \n",
    "        if coefficient == 0:\n",
    "            ard_model_lst.remove((feature, coefficient))\n",
    "\n",
    "            \n",
    "#checking the results\n",
    "for pair in ard_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9a083",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Building model using KNN regression method to check if the model yields best results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN and standard scaler are imported \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#StandardScaler() object is instantiated\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "#fitting the scaler with birthweight data\n",
    "scaler.fit(birthweight_data)\n",
    "\n",
    "\n",
    "#transforming data after fit\n",
    "x_scaled = scaler.transform(birthweight_data)\n",
    "\n",
    "\n",
    "#converting scaled data into a DataFrame\n",
    "x_scaled_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "x_scaled_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding labels to the scaled DataFrame\n",
    "x_scaled_df.columns = birthweight_data.columns\n",
    "\n",
    "#  Checking pre- and post-scaling of the data\n",
    "print(f\"\"\"\n",
    "Dataset BEFORE Scaling\n",
    "----------------------\n",
    "{np.var(birthweight_data)}\n",
    "\n",
    "\n",
    "Dataset AFTER Scaling\n",
    "----------------------\n",
    "{np.var(x_scaled_df)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cbecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unscaled Dataset\n",
    "\n",
    "# subsetting the original dataset\n",
    "birthweight_subset = birthweight_data.loc[ : , ['meduc', 'drink', 'cigs', 'fage']]\n",
    "\n",
    "\n",
    "# UNSCALED correlation matrix\n",
    "df_corr = birthweight_subset.corr().round(2)\n",
    "\n",
    "\n",
    "# setting figure size and plot window\n",
    "fig, ax = plt.subplots(figsize = (16, 16))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "\n",
    "# heatmap of UNSCALED correlations\n",
    "sns.heatmap(df_corr,\n",
    "            cmap = 'twilight',\n",
    "            square = True,\n",
    "            annot = True,\n",
    "            cbar = False,\n",
    "            linecolor  = 'black', \n",
    "            linewidths = 0.5)\n",
    "\n",
    "\n",
    "# Scaled Dataset\n",
    "\n",
    "# SCALED correlation matrix\n",
    "df_scaled_corr = x_scaled_df.loc[ : , ['meduc', 'drink', 'cigs', 'fage']].corr().round(2)\n",
    "\n",
    "\n",
    "# titling the plot\n",
    "plt.title(\"BEFORE Standardization\")\n",
    "\n",
    "\n",
    "# setting plot window\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "\n",
    "# heatmap of SCALED correlations\n",
    "sns.heatmap(df_scaled_corr,\n",
    "            cmap = 'twilight',\n",
    "            square = True,\n",
    "            annot = True,\n",
    "            cbar = False,\n",
    "            linecolor  = 'black',\n",
    "            linewidths = 0.5)\n",
    "\n",
    "\n",
    "# titling the plot\n",
    "plt.title(\"AFTER Standardization\")\n",
    "plt.savefig('./__analysis_images/Corrplots Before and After Scaling_birthweight.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b627434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x_scaled_df,\n",
    "            birthweight_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a KNN model object\n",
    "knn_reg = KNeighborsRegressor(algorithm = 'auto',\n",
    "                              n_neighbors = 5)\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "knn_fit = knn_reg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "knn_reg_pred = knn_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('KNN Training Score:', knn_reg.score(x_train, y_train).round(4))\n",
    "print('KNN Testing Score :', knn_reg.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "knn_reg_score_train = knn_reg.score(x_train, y_train).round(4)\n",
    "knn_reg_score_test  = knn_reg.score(x_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('KNN Train-Test Gap:', abs(knn_reg_score_train - knn_reg_score_test).round(4))\n",
    "knn_reg_test_gap = abs(knn_reg_score_train - knn_reg_score_test).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a38e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists for training set accuracy and test set accuracy\n",
    "training_accuracy = []\n",
    "test_accuracy     = []\n",
    "\n",
    "\n",
    "# building a visualization of 1 to 50 neighbors\n",
    "neighbors_settings = range(1, 51)\n",
    "\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # Building the model\n",
    "    clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    # Recording the training set accuracy\n",
    "    training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "    # Recording the generalization accuracy\n",
    "    test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "# plotting the visualization\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the optimal number of neighbors\n",
    "opt_neighbors = test_accuracy.index(max(test_accuracy)) + 1\n",
    "print(f\"\"\"The optimal number of neighbors is {opt_neighbors}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda33740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving all the birthweight prediction into an excel\n",
    "prediction_results = pd.DataFrame(data = {\n",
    "    'Original Birthweight' : y_test_FULL,\n",
    "    'LR Predictions'       : lr_pred.round(decimals = 2),\n",
    "    'Lasso Predictions'    : lasso_pred.round(decimals = 2),\n",
    "    'ARD Predictions'      : ard_pred.round(decimals = 2),\n",
    "    'LR Deviation'         : lr_pred.round(decimals = 2) - y_test_FULL,\n",
    "    'Lasso Deviation'      : lasso_pred.round(decimals = 2) - y_test_FULL,\n",
    "    'ARD Deviation'        : ard_pred.round(decimals = 2) - y_test_FULL,\n",
    "    })\n",
    "\n",
    "\n",
    "prediction_results.to_excel(excel_writer = './__model_results/linear_model_predictions_birthweight.xlsx',\n",
    "                            index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing model results\n",
    "\n",
    "print(f\"\"\"\n",
    "Model      Train Score      Test Score       Difference\n",
    "-----      -----------      ----------       ----------\n",
    "OLS        {lr_train_score}           {lr_test_score}            {lr_test_gap}\n",
    "Lasso      {lasso_train_score}           {lasso_test_score}            {lasso_test_gap}\n",
    "**ARD**    {ard_train_score}           {ard_test_score}            {ard_test_gap}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "#creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Type'    : ['OLS', 'Lasso', 'ARD'],\n",
    "           \n",
    "    'Training' : [lr_train_score, lasso_train_score,\n",
    "                                   ard_train_score],\n",
    "           \n",
    "    'Testing'  : [lr_test_score, lasso_test_score,\n",
    "                                   ard_test_score],\n",
    "                    \n",
    "    'Train-Test Gap' : [lr_test_gap, lasso_test_gap,\n",
    "                                        ard_test_gap],\n",
    "                    \n",
    "    'Model Size' : [len(lr_model_lst), len(lasso_model_lst),\n",
    "                                    len(ard_model_lst)],\n",
    "                    \n",
    "    'Model' : [lr_model_lst, lasso_model_lst, ard_model_lst]}\n",
    "\n",
    "\n",
    "#converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "#sending model results to Excel\n",
    "model_performance.to_excel('./__model_results/linear_model_performance_birthweight.xlsx',\n",
    "                           index = False)\n",
    "\n",
    "print(f\"\"\"ARD had the highest test score and hence my final model.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c274a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
